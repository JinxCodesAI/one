# AI API Service Configuration

# Server Configuration
PORT=8000
HOST=0.0.0.0

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: custom base URL
# OPENAI_DEFAULT_MODEL=gpt-4o-nano           # Optional: default model for OpenAI

# Google Generative AI Configuration
GOOGLE_GENERATIVE_AI_API_KEY=your-google-api-key-here
# GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1beta  # Optional: custom base URL
# GOOGLE_DEFAULT_MODEL=gemini-1.5-flash      # Optional: default model for Google

# OpenRouter Configuration (for Anthropic and other models)
OPENROUTER_API_KEY=your-openrouter-api-key-here
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1  # Optional: custom base URL
# OPENROUTER_DEFAULT_MODEL=anthropic/claude-3.5-sonnet  # Optional: default model for OpenRouter

# Service Configuration
AI_DEFAULT_MODEL=gpt-4o-nano  # Optional: overall default model

# Custom Model Mappings (Optional)
# AI_MODELS='[{"name":"custom-gpt","provider":"openai","modelId":"gpt-4","isDefault":false}]'

# Instructions:
# 1. Copy this file to .env
# 2. Replace the placeholder values with your actual API keys
# 3. Uncomment and modify optional settings as needed
# 4. At least one provider (OpenAI, Google, or OpenRouter) must be configured
